# =============================================================================
# OmniAI Backend - Full Stack Docker Compose
# =============================================================================
# This is the SINGLE SOURCE OF TRUTH for backend deployment.
#
# Usage:
#   Full stack (Cloudflare):   docker compose up -d
#   Full stack (no tunnel):    docker compose up -d
#   Stop all:                  docker compose down
#   View logs:                 docker compose logs -f
#
# Services:
#   - backend:     FastAPI application (port 8000 internal)
#   - postgres:    PostgreSQL 16 database
#   - redis:       Redis 7 cache/sessions
#   - cloudflared: Cloudflare Tunnel (recommended for external access)
#   - ngrok:       ngrok tunnel (DEPRECATED - use Cloudflare instead)
# =============================================================================

services:
  # ===========================================================================
  # PostgreSQL Database
  # ===========================================================================
  postgres:
    image: postgres:16-alpine
    container_name: omniai-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: omniai
      POSTGRES_USER: omniai
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-omniai_secure_2024}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    expose:
      - "5432"
    networks:
      - omniai_internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U omniai -d omniai"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ===========================================================================
  # Redis Cache & Sessions
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: omniai-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    expose:
      - "6379"
    networks:
      - omniai_internal
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s

  # ===========================================================================
  # Backend API Service
  # ===========================================================================
  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: omniai-backend
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      HOST: "0.0.0.0"
      PORT: "8000"
      LOG_FILE: /app/logs/omniai.log
      # Override database to use PostgreSQL
      DATABASE_URL: postgresql://omniai:${POSTGRES_PASSWORD:-omniai_secure_2024}@postgres:5432/omniai
      # Redis connection
      REDIS_URL: redis://redis:6379/0
    volumes:
      - backend_data:/app/data
      - backend_logs:/app/logs
    # Bind to 127.0.0.1 only to prevent LAN exposure
    # Use "8000:8000" without prefix for all-interfaces binding (containers only)
    # No ports exposed - backend is internal only
    # Access via Cloudflare Tunnel (cloudflared service) or localhost only
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 20s
    networks:
      - omniai_internal
    extra_hosts:
      - "host.docker.internal:host-gateway"
    user: root

  # ===========================================================================
  # Cloudflare Tunnel (recommended for external access)
  # ===========================================================================
  # See docs/CLOUDFLARE_TUNNEL.md for setup instructions
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: omniai-cloudflared
    restart: unless-stopped
    command: >-
      tunnel --url http://backend:8000
    volumes:
      - ./cloudflared/credentials.json:/etc/cloudflared/credentials.json:ro
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - omniai_internal
    profiles:
      - tunnel

  # ===========================================================================
  # Ngrok Tunnel (DEPRECATED - use Cloudflare instead)
  # ===========================================================================
  # ngrok free tier strips Set-Cookie headers, breaking cross-site authentication
  # See docs/CLOUDFLARE_TUNNEL.md for migration to Cloudflare Tunnel
  ngrok:
    image: ngrok/ngrok:latest
    container_name: omniai-ngrok
    restart: unless-stopped
    command: >-
      http backend:8000
      --log=stdout
      --domain=${NGROK_DOMAIN:-rossie-chargeful-plentifully.ngrok-free.dev}
    environment:
      NGROK_AUTHTOKEN: ${NGROK_AUTHTOKEN}
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - omniai_internal
    profiles:
      - tunnel

# =============================================================================
# Volumes (persistent data)
# =============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  backend_data:
    driver: local
  backend_logs:
    driver: local

# =============================================================================
# Networks
# =============================================================================
networks:
  omniai_internal:
    driver: bridge
    # Not internal - allows egress to host.docker.internal for LM Studio/Ollama
