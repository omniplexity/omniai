# OmniAI Backend Configuration (example)

# =============================================================================
# SERVER
# =============================================================================
# ENVIRONMENT: development, staging, or production
ENVIRONMENT=development
# HOST: Bind to 127.0.0.1 for localhost-only access (recommended for dev).
# In containers, use 0.0.0.0 to allow internal network access.
HOST=127.0.0.1
PORT=8000
DEBUG=false
LOG_LEVEL=INFO

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
# Production deployments are validated by startup_checks.py
# Invalid configuration will prevent the backend from starting
# See: backend/core/startup_checks.py for validation rules

# Set a stable, high-entropy key in production.
SECRET_KEY=change-me

# CORS allowed origins (comma-separated). In production, this should be only your
# GitHub Pages origin(s), e.g. https://omniplexity.github.io
#
# NOTE: Do NOT add tunnel domains (ngrok, cloudflare) here. The browser Origin
# is always the frontend domain (GitHub Pages). Tunnel domains handle TLS
# termination but don't need CORS configuration.
#
# For baseline deployment (omniplexity.github.io + ngrok):
CORS_ORIGINS=https://omniplexity.github.io

# ALLOWED_HOSTS: Valid hostnames for the API. Include your tunnel domain for
# production deployments (e.g., cloudflared, bore, or custom domain).
#
# IMPORTANT FOR NGROK:
# - Use wildcard pattern for dynamic hostnames:
#   ALLOWED_HOSTS=localhost,127.0.0.1,*.ngrok-free.app
#
# IMPORTANT FOR QUICK TUNNEL (trycloudflare.com):
# - Use wildcard pattern to avoid restarting backend when hostname changes:
#   ALLOWED_HOSTS=localhost,127.0.0.1,*.trycloudflare.com
#
# For persistent tunnels (custom domain in Cloudflare DNS), use exact hostname:
#   ALLOWED_HOSTS=localhost,127.0.0.1,api.omniplexity.yourdomain.com
#
# In production, this MUST include your backend hostname. Wildcards are supported.
ALLOWED_HOSTS=localhost,127.0.0.1,rossie-chargeful-plentifully.ngrok-free.dev

# Rate limiting (requests per minute per IP)
RATE_LIMIT_RPM=200

# Max request body size in bytes
MAX_REQUEST_BYTES=10485760
VOICE_MAX_REQUEST_BYTES=26214400

# =============================================================================
# AUTHENTICATION
# =============================================================================
SESSION_COOKIE_NAME=omni_session
SESSION_TTL_SECONDS=604800
COOKIE_SECURE=true
# Cookie SameSite policy:
#   Cross-site (GitHub Pages -> tunnel/different domain): SameSite=None + Secure=true (REQUIRED)
#   Same-site (custom domain subdomains):                 SameSite=Lax acceptable
#   Local development (localhost):                        SameSite=Lax acceptable
# Wrong setting causes: "login works but subsequent calls are unauthenticated"
# Production startup_checks.py enforces None for cross-site deployments.
COOKIE_SAMESITE=none
COOKIE_DOMAIN=

CSRF_HEADER_NAME=X-CSRF-Token
CSRF_COOKIE_NAME=omni_csrf
INVITE_REQUIRED=true

# Bootstrap admin (runs only if no admin exists). Recommended: keep disabled
# by default and enable only for first-time setup.
BOOTSTRAP_ADMIN_ENABLED=false
BOOTSTRAP_ADMIN_USERNAME=
BOOTSTRAP_ADMIN_EMAIL=
BOOTSTRAP_ADMIN_PASSWORD=

# =============================================================================
# DATABASE
# =============================================================================
# For local dev without Docker: SQLite (auto-created in backend/data/)
DATABASE_URL=sqlite:///./data/omniai.db

# For Docker Compose: PostgreSQL is used automatically via DATABASE_URL override
# in deploy/docker-compose.yml. Set DATABASE_URL_POSTGRES here for reference:
DATABASE_URL_POSTGRES=postgresql://omniai:${POSTGRES_PASSWORD:-omniai_secure_2024}@postgres:5432/omniai

# =============================================================================
# MEDIA
# =============================================================================
MEDIA_STORAGE_PATH=./data/uploads

# =============================================================================
# PROVIDERS
# =============================================================================
PROVIDER_DEFAULT=lmstudio
PROVIDERS_ENABLED=lmstudio
PROVIDER_TIMEOUT_SECONDS=60
PROVIDER_MAX_RETRIES=3
SSE_PING_INTERVAL_SECONDS=30
READINESS_CHECK_PROVIDERS=false

LMSTUDIO_BASE_URL=http://host.docker.internal:1234
OLLAMA_BASE_URL=http://127.0.0.1:11434

# OpenAI-compatible (optional)
OPENAI_COMPAT_BASE_URL=
OPENAI_COMPAT_API_KEY=

# =============================================================================
# EMBEDDINGS (semantic search / RAG)
# =============================================================================
# To enable semantic search, set EMBEDDINGS_ENABLED=true and ensure you have at
# least one enabled provider that supports embeddings (e.g. openai_compat or ollama).
EMBEDDINGS_ENABLED=false
EMBEDDINGS_MODEL=
EMBEDDINGS_PROVIDER_PREFERENCE=openai_compat,ollama,lmstudio

# =============================================================================
# VOICE
# =============================================================================
VOICE_PROVIDER_PREFERENCE=whisper,openai_compat
VOICE_WHISPER_MODEL=base
VOICE_WHISPER_DEVICE=cpu
VOICE_OPENAI_AUDIO_MODEL=whisper-1

# =============================================================================
# REDIS
# =============================================================================
REDIS_URL=redis://redis:6379/0
